source:
  type: custom-s3
  serviceName: Datalake storage
  serviceConnection:
    config:
      type: CustomDatabase
      sourcePythonClass: connectors.s3.s3_connector.S3Source  # <-- Your custom class
      connectionOptions:
        awsAccessKeyId: openmetadata_user
        awsSecretAccessKey: i3fEkwPvAxahp5frRzY8YEDde68TY5cX
        awsRegion: us-east-1
        endPointURL: http://minio:9000
        bucketName: farm-bucket-name
        file_formats: "csv,json,parquet,tsv"
        enable_partition_parsing: "true"
        # Format: "keyword:TagFQN;keyword:TagFQN"
        tag_mapping: "utilisateurs:PII.Sensitive;events:Application.Events;orders:Commerce.Orders"
        default_tags: "Tier.Bronze"
        # The number of rows to ingest for sample data. Default is 50.
        sample_size: "100"

  sourceConfig:
    config:
      type: StorageMetadata
      # Your custom configuration for the connector

sink:
  type: metadata-rest
  config: {}

workflowConfig:
  loggerLevel: DEBUG
  openMetadataServerConfig:
    hostPort: http://localhost:8585/api
    authProvider: openmetadata
    securityConfig:
      # IMPORTANT: Make sure this token is valid at runtime.
      jwtToken: "eyJraWQiOiJHYjM4OWEtOWY3Ni1nZGpzLWE5MmotMDI0MmJrOTQzNTYiLCJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJvcGVuLW1ldGFkYXRhLm9yZyIsInN1YiI6ImluZ2VzdGlvbi1ib3QiLCJyb2xlcyI6WyJJbmdlc3Rpb25Cb3RSb2xlIl0sImVtYWlsIjoiaW5nZXN0aW9uLWJvdEBvcGVuLW1ldGFkYXRhLm9yZyIsImlzQm90Ijp0cnVlLCJ0b2tlblR5cGUiOiJCT1QiLCJpYXQiOjE3NTE0ODU5OTksImV4cCI6bnVsbH0.csOeKzpzZWFIvCP9JgomVyea7Rqbs-FkPywzaZi5oIo34szgOuN_d6Kz69IT3F-NhPE0MJjVEe7K61X89duKX9TjBUm7SuTPq27OYfanvZp-28xL4QTAryeXwzVrGCDH0q-6ZqONIvBcwk8HNONH474hjT1q0hpwtrUZx9PW9L3JzrBR60P316H8QpDNVvDVMQLsyLBRClZdpqPDXX5zsXEANVSZC6G_R6Dkh0MBtgOAeURvdcRkINwPsvgfq-flTjsJM-tUUNxasfgKed25zMAXqbQP542ctY3BYvhhtWxn-gvgztg_gRlwy2fMrC6hFmNYXLt2lqwHgIuqE-drgw"