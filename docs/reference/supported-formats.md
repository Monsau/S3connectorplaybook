# ğŸ“Š Supported File Formats

Complete reference for all file formats supported by the OpenMetadata S3 Connector.

## Format Overview

```mermaid
graph TD
    Connector[ğŸ”Œ S3 Connector] --> Text[ğŸ“ Text Formats]
    Connector --> Columnar[ğŸ—ƒï¸ Columnar Formats]
    Connector --> Office[ğŸ“‹ Office Formats]
    Connector --> Scientific[ğŸ”¬ Scientific Formats]
    Connector --> Modern[âš¡ Modern Formats]
    
    Text --> CSV[ğŸ“Š CSV]
    Text --> TSV[ğŸ“Š TSV]
    Text --> JSON[ğŸ“„ JSON]
    Text --> JSONL[ğŸ“„ JSONL]
    
    Columnar --> Parquet[ğŸ—ƒï¸ Parquet]
    Columnar --> ORC[ğŸ—ƒï¸ ORC]
    Columnar --> Avro[ğŸ—ƒï¸ Avro]
    Columnar --> Feather[ğŸ—ƒï¸ Feather]
    
    Office --> Excel[ğŸ“‹ Excel XLSX]
    Office --> ExcelLegacy[ğŸ“‹ Excel XLS]
    
    Scientific --> HDF5[ğŸ”¬ HDF5]
    Scientific --> Pickle[ğŸ”¬ Pickle]
    
    Modern --> Delta[âš¡ Delta Lake]
    
    style Connector fill:#e8f5e8
    style Text fill:#e3f2fd
    style Columnar fill:#fff3e0
    style Office fill:#f3e5f5
    style Scientific fill:#e8f5e8
    style Modern fill:#fce4ec
```

## Detailed Format Support

### Text Formats

#### CSV (Comma-Separated Values)
- **Extensions**: `.csv`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Automatic
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Automatic delimiter detection
- Header row detection
- Data type inference
- Encoding detection (UTF-8, Latin-1)
- Custom separators support

**Configuration**:
```yaml
connectionOptions:
  file_formats: "csv"
  csv_delimiter: ","      # Optional: auto-detected
  csv_header: "true"      # Optional: auto-detected
  csv_encoding: "utf-8"   # Optional: auto-detected
```

#### TSV (Tab-Separated Values)
- **Extensions**: `.tsv`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Automatic
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Tab delimiter handling
- Similar to CSV with tab separation
- Robust parsing for complex data

#### JSON (JavaScript Object Notation)
- **Extensions**: `.json`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Nested structures
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Nested object flattening
- Array handling
- Complex data type support
- Schema inference from structure

#### JSONL (JSON Lines)
- **Extensions**: `.jsonl`, `.ndjson`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Automatic
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Line-by-line JSON processing
- Large file streaming support
- Memory-efficient parsing
- Schema merging across records

### Columnar Formats

#### Parquet
- **Extensions**: `.parquet`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Native schema
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Native + Hive

**Features**:
- Native schema preservation
- Efficient compression
- Nested data structures
- Predicate pushdown for sampling

**Metadata Extracted**:
```mermaid
graph LR
    Parquet[ğŸ“„ Parquet File] --> Schema[ğŸ“‹ Schema]
    Parquet --> Stats[ğŸ“Š Statistics]
    Parquet --> Compression[ğŸ—œï¸ Compression Info]
    
    Schema --> Columns[ğŸ“ Column Names]
    Schema --> Types[ğŸ·ï¸ Data Types]
    Schema --> Nested[ğŸŒ³ Nested Structures]
    
    Stats --> RowCount[ğŸ“Š Row Count]
    Stats --> FileSize[ğŸ“ File Size]
    Stats --> Partitions[ğŸ—‚ï¸ Partition Info]
```

#### ORC (Optimized Row Columnar)
- **Extensions**: `.orc`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Native schema
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Native + Hive

**Features**:
- Native ORC schema reading
- Stripe-level metadata
- Built-in compression support
- ACID transaction information

#### Avro
- **Extensions**: `.avro`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Embedded schema
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Embedded schema evolution
- Complex data types (unions, arrays, maps)
- Schema registry integration ready
- Compression codec support

#### Feather
- **Extensions**: `.feather`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Native schema
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Apache Arrow format
- Fast read/write operations
- Cross-language compatibility
- Memory-mapped access

### Office Formats

#### Excel XLSX
- **Extensions**: `.xlsx`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Multi-sheet
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Sheet-based

**Features**:
- Multiple worksheet support
- Header row detection
- Data type inference
- Cell formatting preservation

**Excel-Specific Configuration**:
```yaml
connectionOptions:
  excel_sheet_name: "Sheet1"    # Optional: process specific sheet
  excel_header_row: "1"         # Optional: header row number
  excel_skip_rows: "0"          # Optional: rows to skip
```

#### Excel XLS (Legacy)
- **Extensions**: `.xls`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Multi-sheet
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Sheet-based

### Scientific Formats

#### HDF5 (Hierarchical Data Format)
- **Extensions**: `.h5`, `.hdf5`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Dataset structure
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Group-based

**Features**:
- Hierarchical dataset structure
- Multi-dimensional arrays
- Metadata preservation
- Group and dataset browsing

**HDF5 Structure Mapping**:
```mermaid
graph TD
    HDF5[ğŸ“„ HDF5 File] --> Root[ğŸŒ³ Root Group]
    Root --> Groups[ğŸ“ Groups]
    Root --> Datasets[ğŸ“Š Datasets]
    
    Groups --> SubGroups[ğŸ“ Sub-groups]
    Groups --> SubDatasets[ğŸ“Š Sub-datasets]
    
    Datasets --> Arrays[ğŸ”¢ N-D Arrays]
    Datasets --> Metadata[ğŸ·ï¸ Attributes]
    
    Arrays --> Dimensions[ğŸ“ Dimensions]
    Arrays --> DataTypes[ğŸ·ï¸ Data Types]
```

#### Pickle
- **Extensions**: `.pkl`, `.pickle`
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Object inspection
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Hive-style

**Features**:
- Python object serialization
- Complex object structure support
- Pandas DataFrame detection
- Security considerations handled

### Modern Formats

#### Delta Lake
- **Extensions**: `.delta` (directory-based)
- **Status**: âœ… Full Support
- **Schema Detection**: âœ… Transaction log
- **Sample Data**: âœ… Supported
- **Partition Support**: âœ… Native partitioning

**Features**:
- ACID transactions
- Time travel capabilities
- Schema evolution tracking
- Optimize and vacuum operations

**Delta Lake Metadata**:
```mermaid
graph LR
    Delta[ğŸ“ Delta Table] --> Log[ğŸ“ Transaction Log]
    Delta --> Data[ğŸ“„ Parquet Files]
    
    Log --> Commits[ğŸ“‹ Commits]
    Log --> Schema[ğŸ“Š Schema History]
    Log --> Partitions[ğŸ—‚ï¸ Partition Info]
    
    Data --> Current[ğŸ“„ Current Data]
    Data --> Historical[ğŸ“„ Historical Data]
```

## Format Detection Logic

```mermaid
sequenceDiagram
    participant Scanner
    participant Detector
    participant Factory
    participant Parser
    
    Scanner->>Detector: File Path
    Detector->>Detector: Extract Extension
    Detector->>Detector: Check Magic Bytes
    Detector->>Factory: Format Identified
    Factory->>Parser: Create Parser
    Parser-->>Scanner: Ready to Process
```

## Performance Characteristics

### Read Performance

| Format | Small Files | Large Files | Memory Usage | CPU Usage |
|--------|-------------|-------------|--------------|-----------|
| CSV | â­â­â­ | â­â­ | ğŸŸ¢ Low | ğŸŸ¢ Low |
| JSON | â­â­ | â­ | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| Parquet | â­â­â­â­ | â­â­â­â­â­ | ğŸŸ¢ Low | ğŸŸ¢ Low |
| ORC | â­â­â­â­ | â­â­â­â­â­ | ğŸŸ¢ Low | ğŸŸ¢ Low |
| Avro | â­â­â­ | â­â­â­â­ | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| Excel | â­â­ | â­ | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| HDF5 | â­â­â­ | â­â­â­â­ | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| Delta | â­â­â­â­ | â­â­â­â­â­ | ğŸŸ¢ Low | ğŸŸ¢ Low |

### Schema Detection Speed

```mermaid
xychart-beta
    title "Schema Detection Performance"
    x-axis [CSV, JSON, Parquet, ORC, Avro, Excel, HDF5, Delta]
    y-axis "Time (seconds)" 0 --> 10
    bar [2, 4, 1, 1, 2, 6, 3, 1]
```

## Configuration Examples

### All Formats Enabled
```yaml
connectionOptions:
  file_formats: "csv,tsv,json,jsonl,parquet,orc,avro,feather,xlsx,xls,h5,hdf5,pkl,pickle,delta"
```

### Performance Optimized
```yaml
connectionOptions:
  file_formats: "parquet,orc,delta"  # Fast columnar formats only
  max_sample_rows: "1000"
```

### Text-Only Processing
```yaml
connectionOptions:
  file_formats: "csv,tsv,json,jsonl"
  text_encoding: "utf-8"
```

### Scientific Data Focus
```yaml
connectionOptions:
  file_formats: "hdf5,pickle,parquet"
  enable_nested_schema: "true"
```

## Limitations and Considerations

### File Size Limits
- **Large Files**: Files > 1GB may require streaming mode
- **Memory Usage**: Configure `max_sample_rows` for large files
- **Timeout Settings**: Adjust for slow network connections

### Format-Specific Limitations

#### Excel
- Maximum 1,048,576 rows per sheet
- Complex formulas not evaluated
- Merged cells handled as single values

#### HDF5
- Very large datasets may require chunked reading
- Complex hierarchies can impact performance

#### Pickle
- Security considerations with untrusted files
- Python version compatibility requirements

## Error Handling

### Common Error Patterns
```mermaid
graph TD
    Error[âŒ Parsing Error] --> Type{Error Type}
    
    Type -->|Format| UnsupportedFormat[ğŸš« Unsupported Format]
    Type -->|Corruption| CorruptedFile[ğŸ’¥ Corrupted File]
    Type -->|Access| AccessDenied[ğŸ”’ Access Denied]
    Type -->|Memory| OutOfMemory[ğŸ’¾ Out of Memory]
    
    UnsupportedFormat --> Skip[â­ï¸ Skip File]
    CorruptedFile --> Log[ğŸ“ Log Warning]
    AccessDenied --> Retry[ğŸ”„ Retry with Auth]
    OutOfMemory --> Reduce[ğŸ“‰ Reduce Sample Size]
    
    Skip --> Continue[âœ… Continue Processing]
    Log --> Continue
    Retry --> Continue
    Reduce --> Continue
```

### Graceful Degradation
- Unsupported formats are skipped with warnings
- Partial schema extraction for corrupted files
- Fallback to basic metadata for complex structures

## Future Format Support

### Planned Additions
- **Apache Iceberg**: Modern table format
- **Apache Hudi**: Incremental data processing
- **Protocol Buffers**: Serialized structured data
- **MessagePack**: Efficient binary serialization

### Community Requests
- **XML**: Structured markup language
- **YAML**: Human-readable data serialization
- **Apache Arrow**: In-memory columnar format

## Next Steps

- ğŸš€ **[Quick Start](../user-guides/quick-start.md)** - Get started with file formats
- âš™ï¸ **[Configuration](../user-guides/configuration.md)** - Format-specific configuration
- ğŸ—ï¸ **[Architecture](../developer-guides/architecture.md)** - Parser architecture
- ğŸ”§ **[Extending Parsers](../developer-guides/extending-parsers.md)** - Add new formats
